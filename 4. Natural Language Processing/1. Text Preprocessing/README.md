# ‚úÇÔ∏è Text Preprocessing

> Understanding the foundations of text cleaning, normalization, and representation for downstream NLP tasks.

---

## üß© Concepts
Preprocessing transforms raw text into structured data suitable for ML models.

Key topics:
- Tokenization and normalization
- Stopword removal
- Lemmatization / Stemming
- Vectorization (BoW, TF-IDF)
- Word embeddings overview (Word2Vec, GloVe)

---

## ‚öôÔ∏è Implementation Plan
- [ ] Tokenize sample sentences (NLTK, spaCy)
- [ ] Apply lowercasing, punctuation removal, stopword filtering
- [ ] Compare **stemming vs lemmatization**
- [ ] Create **BoW** and **TF-IDF** representations
- [ ] Visualize embedding spaces (PCA or t-SNE)

---

## üìö Resources
- *Speech and Language Processing* ‚Äî Jurafsky & Martin  
- NLTK / spaCy Documentation  
- scikit-learn Text Feature Extraction Guide  
- FastText / Gensim Tutorials

---

## ‚úÖ Progress
- [ ] Tokenization complete  
- [ ] Vectorization implemented  
- [ ] Embeddings visualized  
- [ ] Notes written  
