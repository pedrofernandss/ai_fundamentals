# 🧠 Machine Learning

> Exploring core supervised and unsupervised algorithms for predictive modeling and pattern discovery.

---

## 🧩 Concepts

Machine Learning develops models that learn from data to make predictions or decisions.  
This module includes both **supervised** (classification, regression) and **unsupervised** (clustering, dimensionality reduction) learning techniques.

Core topics:
- Forecasting
- Classification
- Clustering
- Dimensionality Reduction
- Model Evaluation & Metrics
- Anomaly Detection

---

## ⚙️ Implementation Plan

- [ ] Implement linear and polynomial regression  
- [ ] Train and evaluate classification models (Logistic, SVM, Random Forest, XGBoost)  
- [ ] Apply clustering (K-Means, DBSCAN)  
- [ ] Perform dimensionality reduction (PCA)  
- [ ] Test anomaly detection algorithms  
- [ ] Build model evaluation utilities  

---

## 📊 Evaluation Metrics

- Regression: RMSE, MAE, R²  
- Classification: Accuracy, Precision, Recall, F1, ROC-AUC  
- Clustering: Silhouette Score, Davies–Bouldin Index  
- Anomaly Detection: Precision/Recall, ROC Curve  

---

## 🧪 Experiments & Insights

- Compare bias–variance trade-offs across models  
- Visualize decision boundaries and cluster assignments  
- Evaluate the effect of feature scaling  
- Explore cross-validation and hyperparameter tuning  

---

## 📚 Resources

- *Pattern Recognition and Machine Learning* — C. M. Bishop  
- *Hands-On Machine Learning* — Aurélien Géron  
- scikit-learn Documentation  
- Andrew Ng — Machine Learning Specialization (Coursera)

---

## ✅ Progress

- [ ] Regression implemented  
- [ ] Classification models compared  
- [ ] Clustering evaluated  
- [ ] PCA applied  
- [ ] Metrics analyzed  
